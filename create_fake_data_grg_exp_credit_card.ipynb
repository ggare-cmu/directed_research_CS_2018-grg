{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from torch import nn, optim\n",
    "from torch.autograd.variable import Variable\n",
    "from torchvision import transforms, datasets\n",
    "from data_treatment import DataSet, DataAtts\n",
    "from discriminator import *\n",
    "from generator import *\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7630b1321e8b437a8361a7390fb4067f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Folder:', options=('models/credit_card_fraud-size0_TrainUpsampledPatient', 'models/credi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "folder = widgets.Dropdown(\n",
    "    options=glob.glob(\"models/credit_card*\"),\n",
    "    description='Folder:',\n",
    "    # value=\"models/diabetes_escalonated\",\n",
    "    disabled=False,\n",
    ")\n",
    "display(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb41b1cbe58b4605ae050b5a01c017b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Generator:', options=('models/credit_card_fraud-size4_TrainUpsampledPatient/generatorcre…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "folder_name = folder.value+\"/generator*.pt\"\n",
    "model_widget = widgets.Dropdown(\n",
    "    options=glob.glob(folder_name),\n",
    "    description='Generator:',\n",
    "    disabled=False,\n",
    ")\n",
    "display(model_widget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_db_name = folder.value[7:]\n",
    "# original_db_path = \"original_data/\" + original_db_name + \".csv\"\n",
    "original_db_path = \"grg_credit_card/\" + original_db_name + \".csv\"\n",
    "original_db = pd.read_csv(original_db_path)\n",
    "original_db_size=original_db.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    checkpoint= torch.load(model_widget.value, map_location='cuda')\n",
    "except:\n",
    "    checkpoint= torch.load(model_widget.value, map_location='cpu')\n",
    "checkpoint['model_attributes']['out_features'] = len(original_db.columns)\n",
    "checkpoint['model_attributes']['hidden_layers'] = [512, 256]\n",
    "generator = GeneratorNet(**checkpoint['model_attributes'])\n",
    "generator.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"fake_data/\" + original_db_name ):\n",
    "    os.makedirs(\"fake_data/\" + original_db_name )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size = original_db_size\n",
    "# size = 200\n",
    "# size = 50\n",
    "num_samples = 10000\n",
    "synthetic_data = generator.create_data(100*num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pre-Downsampling] syn_classes, syn_class_count = (array([False,  True]), array([504521, 495479]))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "syn_labels = synthetic_data[:,-1] > 0.5\n",
    "syn_classes, syn_class_count = np.unique(syn_labels, return_counts = True)\n",
    "print(f\"[Pre-Downsampling] syn_classes, syn_class_count = {syn_classes, syn_class_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame(synthetic_data, columns=original_db.columns)\n",
    "#Changes the name to be easier to read\n",
    "# name = model_widget.value.split(\"/\")[-1][10:-4] + \"_size-\" + str(size)\n",
    "name = original_db_name + \"_size-\" + str(num_samples)\n",
    "df.to_csv( \"fake_data/\" + original_db_name + \"/\" + name + \".csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pre-Downsampling] syn_classes, syn_class_count = (array([ True]), array([1000000]))\n",
      "syn_classes, syn_class_count = (array([ True]), array([10000]))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "syn_labels = synthetic_data[:,-1] > 0.5\n",
    "syn_classes, syn_class_count = np.unique(syn_labels, return_counts = True)\n",
    "print(f\"[Pre-Downsampling] syn_classes, syn_class_count = {syn_classes, syn_class_count}\")\n",
    "\n",
    "per_cls_sample = int(num_samples/len(syn_classes))\n",
    "c_idx_list = []\n",
    "for c in syn_classes:\n",
    "    c_idx = np.where(syn_labels == c)[0]\n",
    "    c_idx = np.random.choice(c_idx, per_cls_sample, replace = len(c_idx) < per_cls_sample)\n",
    "    c_idx_list.extend(c_idx)\n",
    "\n",
    "if len(c_idx_list) < num_samples:\n",
    "    c_idx_list.extend(c_idx[:num_samples - len(c_idx_list)])\n",
    "\n",
    "synthetic_data = synthetic_data[c_idx_list]\n",
    "assert synthetic_data.shape[0] == num_samples, \"Error! Selecting samples from a large batch failed.\"\n",
    "\n",
    "syn_classes, syn_class_count = np.unique(synthetic_data[:, -1] > 0.5, return_counts = True)\n",
    "print(f\"syn_classes, syn_class_count = {syn_classes, syn_class_count}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame(synthetic_data, columns=original_db.columns)\n",
    "#Changes the name to be easier to read\n",
    "# name = model_widget.value.split(\"/\")[-1][10:-4] + \"_size-\" + str(size)\n",
    "name = original_db_name + \"_size-\" + str(num_samples)\n",
    "df.to_csv( \"fake_data/\" + original_db_name + \"/\" + name + \".csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "29cc6ffbdcf8747eb0d20c8d894243c52566d049a6ec2a8b8a3360bf8c52ae76"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
